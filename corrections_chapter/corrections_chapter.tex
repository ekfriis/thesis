\ifx\master\undefined\input{settings/autocompile}\fi 
%
\chapter{Monte Carlo Corrections} 
%
\label{ch:corrections} One of the most important goals of the analysis is to
minimize the effect of potentially incorrect simulation effects on the final
result.  While the simulated CMS events have been observed to match the 2010
data with surprising results, it is nonetheless critical to measure in real data
phenomenon which can have significant effects on the analysis whenever possible.
In practice, these measurements are used to apply a correction factor to the
corresponding measurement obtained from Monte Carlo.  This measured correction
factor has an associated uncertainty, and is taken into account as a systematic
uncertainty.  The application of systematic uncertainties is described in the
next chapter.   

The corrections measured and used in this analysis can be divided into two
categories, efficiency corrections and scale corrections. Identification
efficiency corrections scale the expected yield (due to a given identification
selection) up or down.  Scale corrections systematically scale the energy of a
particle (or \MET) up or down.  In this analysis we apply efficiency corrections
for the High Level Trigger muon requirement, all stages of muon identification,
and the hadronic tau identification.  We apply a momentum scale correction to
the muon and tau legs, and to the resolution of the \MET\@.  Finally, events are
simulated with overlapping ``pile--up''\footnote{A pile--up event occurs when
there are multiple interactions in one bunch proton bunch crossing.  Pile--up
increases with the instantaneous luminosity provided by the collider.} events.
The simulated events are weighted such that the number of pile--up events in the
simulation matches that observed in the data.

\section{Muon Identification Efficiency} \label{sec:ZmumuTagAndProbe} 
%
The identification efficiencies associated with the muon are measured in $\ZMM$
events using the ``tag and probe'' technique~\cite{CMS-PAS-EWK-10-002}.  $\ZMM$
events are selected from the Muon 7~\TeV CMS 2010
datasets\footnote{\mbox{/Mu/Run2010A-Sep17ReReco\v2/RECO} and
\mbox{/Mu/Run2010B-PromptReco-v2/RECO} } by requiring that the events pass the
``loose'' Vector Boson Task Force (VBTF) event
selections~\cite{CMS-PAS-EWK-10-002}.  In the selected events, we define the
``tag'' muons as those that have transverse momentum greater than 15~\GeVc and
pass the VBTF muon selection.  The tag muons are further required to pass the
``combined relative isolation'' described in the VBTF paper.  We finally require
that the tag muon be matched to an HLT object corresponding to the
run--dependent requirements listed in table~\ref{tab:AHtoMuTauTriggers}.  The
trigger match requirement ensures that the event would be recorded independently
of the probe muon.  After the tag and probe muon pairs have been collected, we
compare the muon identification performance in the probe collection in events
selected in data to the performance in simulated $\ZMM$ events.  The selection
of events and tag muon in the simulated sample is the same as the data sample,
with the notable exception that the only HLT requirement applied in MC is that
the tag muon is matched to an HLT\_Mu9 object.  Any difference in efficiency
between the HLT\_Mu9 path and the paths used to select the data (in the
tag--probe measurement and in the analysis) will be considered implicitly in the
correction faction. 

The efficiencies for the muon selections applied in this analysis are measured
using the ``probe'' objects.  We measure the following marginal efficiencies,
each relative to the previous requirement:
\begin{itemize}
\item Efficiency of global probe muons to satisfy VBTF muon identification
selections.
\item Efficiency of global probe muons passing the VBTF muon identification
selection to satisfy the isolation criteria described in
Section~\ref{sec:MuonId}.
\item Efficiency of probe muons passing the offline analysis selection defined
  in Chapter~\ref{ch:selections} to pass the HLT selection.
\end{itemize}

In each case, the invariant mass spectrum of the tag--probe pair is fitted with
a Crystal Ball function for the signal ($\ZMM$) events and an
exponential for the background.  The fit is done for two cases; where the probe
fails the selection and the where it passes.  The method is illustrated in
Figure~\ref{fig:TagAndProbeFits}.  The signal yield $N$ is extracted from each
fit and the efficiency is computed as $N_{pass}/(N_{pass} + N_{fail}$.  Each
efficiency is measured in both the data and the simulation. The results of the
measurements are shown in table~\ref{tab:muonTagAndProbeResults}. In the final
analysis, the simulated events are weighted by the fractional difference to the
measured values; the statistical uncertainty on the weight is taken as the sum
in quadrature of the statistical uncertainties for the data and simulation
efficiency measurements.  The uncertainty on this measurement is taken as
systematic uncertainty in the final measurement.
\begin{figure}[t]
\begin{center}
%\includegraphics*[height=52mm, viewport=19 0 524
%396]{figures/evtReco_PzetaDefinition.pdf}
\includegraphics*[height=52mm]{corrections_chapter/tag_probe_data/plot_0.pdf}
\includegraphics*[height=52mm]{corrections_chapter/tag_probe_data/plot_1.pdf}
\caption[Tag--probe muon isolation method]{The tag--probe dimuon invariant mass
spectrum in events in which the probe muon passed (left) and failed (right) the
muon isolation requirement.  The solid gives the result of the simultaneous fit
of the signal (real $Z\to\MM$ events) and background.  The fitted background
contribution is shown as the dotted line.  The muon isolation efficiency is then
extracted from the number of signal events in the passing and failing bins.}
\label{fig:TagAndProbeFits}
\end{center}
\end{figure} 

The correction for the trigger efficiency needs to take into account the
differences in the HLT selections applied during different operating periods
(see table~\ref{tab:AHtoMuTauTriggers}).  To determine the overall correction
factor, we measure the trigger efficiency in data for each of the operating
periods and compare it to the simulated efficiency of the HLT\_Mu9 selection.
The overall efficiency in data is taken as the average of the three periods,
weighted by integrated luminosity.

The efficiency of the ``cross--triggers'' used in the run--range period 
$148822-149182$ (period~C) cannot be measured in $\ZMM$ events as they
require a reconstructed PFTau object at the trigger level.  A single muon trigger
(HLT\_Mu15) is also used in period C.  The contribution of the cross--triggers
is taken as a correction to the single muon trigger period C efficiency. The
``muon leg'' of the cross--triggers have the same requirements as the single
muon triggers used in the run--range $147196-148058$ (period~B).  The
``cross--trigger'' contribution is estimated as the difference between the
efficiency in period B and the single--muon period C efficiency multiplied by a
correction factor of $0.9 \pm 10\%$ to account for the $\tau$ leg efficiency.
In the case that the measured single--muon period C efficiency is larger than
the period B efficiency (due to statistical fluctuations and improvements in the
trigger system), the period B efficiency is increased by 2\%.

\begin{table}[t]
\begin{center}
%\tablesize
\begin{tabular}{|l|c|c|c|c|}
\hline
\multirow{2}{*}{Muon selection} &  \multicolumn{2}{c|}{Efficiency} & \multirow{2}{*}{Ratio} & \multirow{2}{*}{Corection} \\ 
&  Data  &          Simulation &      &      \\ 
\hline
% cut                           data      mc     ratio     correction
VBTF identification &   $99.2^{+0.1}_{-0.1}$\%  &  $99.1^{+0.1}_{-0.1}$\% & $1.001^{+0.001}_{-0.001}$ & 1.0\\
Particle Isolation  &  $76.8^{+0.4}_{-0.4}$\% &  $78.3^{+0.3}_{-0.3}$\% & $0.981^{+0.006}_{-0.006}$ & 0.98 \\
Trigger             &   $95.0^{+0.5}_{-0.5}$\% & $96.5^{+0.1}_{-0.2}$\% & $0.984^{+0.006}_{-0.006}$ & 0.98 \\
\hline
\end{tabular}
\end{center}
\begin{center}
\caption[Muon trigger, identification, and isolation correction
factors]{Efficiency of the various global muon selections applied in the
analysis measured in data and simulated $Z\rightarrow\mu^+\mu^-$ events.  The
``correction'' column gives the event weight correction applied to the simulated
events in the final analysis.  The efficiency for each selection is the marginal
efficiency with respect to the selection in the row above it.  }

\label{tab:muonTagAndProbeResults}
\end{center}
\end{table}

\begin{figure}[t]
\begin{center}
%\includegraphics*[height=52mm, viewport=19 0 524
%396]{figures/evtReco_PzetaDefinition.pdf}
\includegraphics*[height=52mm]{corrections_chapter/figures/pt_iso_pt_scaled.pdf}
\includegraphics*[height=52mm]{corrections_chapter/figures/etatrig_iso_abseta_scaled.pdf}
\includegraphics*[height=52mm]{corrections_chapter/figures/pt_trigCompX_pt_scaled.pdf}
\includegraphics*[height=52mm]{corrections_chapter/figures/etatrig_trigCompX_abseta_scaled.pdf}
\caption[Muon isolation correction factors]{Ratio of muon isolation efficiency
measured in data compared to simulated $Z\rightarrow\mu^+\mu^-$ events.}
\label{fig:MuonIsoCorrVersusPt}
\end{center}
\end{figure} 

\section{Hadronic Tau Identification Efficiency}
\label{sec:HadTauIdEff}
%
The hadronic tau identification efficiency has been measured in 2010 7~\TeV CMS
data.  The most straight forward to measure the tau ID efficiency would be to
use a resonance which decays to taus and has a known cross section.  One could
then measure the tau ID efficiency in by comparing the observed yield
$N_\text{obs}$ in data with that expected from the known cross section,
according to the cross section equation,
\begin{equation}
  \varepsilon = \frac{N_\text{obs} - N_\text{bkg}}
  {\mathcal{L} \times \mathcal{A} \times \xbr}.
  \nonumber
\end{equation}
The only suitable resonance for this method is $Z\to\TT$.  This method has been
applied\footnote{Actually, a slightly more complicated method is used. The
analysis uses three decay channels, and the \ZTT cross section and tau
identification correction factors are fitted simultaneously. The central value
of the \ZTT cross section is driven by the $\ZTT \to e \mu$ channel, which is
independent of the hadronic tau identification.} in CMS \ZTT cross section
analysis~\ref{CMS-PAS-EWK-10-013}, and measured a tau identification simulation
to data correction factor of \mbox{$0.960 \pm 0.067$}.

Unfortunately, this method cannot be used in this analysis.  The measurement
using the $Z$ resonance operates on the assumption there is no New Physics
contribution to the events in the $Z$ bump.  In the case that there was a Higgs
signal at $\ma = 90~\GeVcc$, it would be indistinguishable from the $Z$ and
would appear as an increase of $N_{H}$ in the observed yield.  The analysis
would the be completely insensitive to a Higgs boson on the $Z$ peak, and cause
the efficiency to be overestimated by a factor 
\begin{equation}
  \delta \varepsilon = \frac{N_H}
  {\mathcal{L} \times \mathcal{A} \times \xbr}.
  \nonumber
\end{equation}

The solution to this problem is to use a ``tag and probe'' approach analogous to
the muon efficiency measurement of Section~\ref{sec:ZmumuTagAndProbe}.  The tag
and probe method is only sensitive to the shapes of the distributions, and will
be independent of a Higgs contribution to the $Z$ peak.  This measurement has
been performed by the CMS Tau Physics Object Group~\cite{CMS-PAS-TAU-11-001}.  A
loose hadronic tau preselection is applied to events which pass the selections
(excluding the hadronic tau identification) of the CMS EWK \ZTT cross section
measurement~\cite{CMS-PAS-EWK-10-013}.  The preselected sample is then split
into to categories, those that pass the hadronic tau identification and those
that fail.  The signal and background yields in the each category are fitted
using the Template Method described in Section~\ref{sec:template}.  An
illustrative example of the fits for the yields is shown in
Figure~\ref{fig:TauIdEffFits}.  The hadronic tau identification efficiency can
then be computed using the relative size of the true tau yields in the passing
and failing categories.  The efficiency is measured~\cite{CMS-PAS-TAU-11-001}
for the loose \hpsTanc tau identification in the 2010 CMS dataset and is found
to be \mbox{$1.06 \pm 0.30$}. 
%
\begin{figure}
  \centering
  % Use height instead of width due to rotation
  \includegraphics*[height=0.49\textwidth,angle=90]{corrections_chapter/figures/controlPlotsTauIdEff_C1p_diTauVisMassFromJet_tauDiscrTaNCfrOnePercent_fitted.pdf}
  \includegraphics*[height=0.49\textwidth,angle=90]{corrections_chapter/figures/controlPlotsTauIdEff_C1f_diTauVisMassFromJet_tauDiscrTaNCfrOnePercent_fitted.pdf}
  \caption[Measurement of hadronic tau identification efficiency] {Visible mass
  spectrum of preselected events used to measure the hadronic tau identification
  efficiency in 2010 CMS 7~\TeV data.  The figure on the left (right) shows the
  preselected events that pass (fail) the hadronic tau identification.  The
  different colors indicate the fitted yields of the different signal and
  background contributions. Reference:~\cite{CMS-PAS-TAU-11-001}.
  }
  \label{fig:TauIdEffFits}
\end{figure}

\section{Muon and Tau Momentum Scale}
\label{sec:MuonTauMomentumScale} Muons are one of the best measured objects at
CMS\@.  The momentum scale of CMS muons has been measured~\cite{CMS_AN_2010-059}
using the $\JPsi, \psi(2S)$ and $\Upsilon$ di--muon resonant decays.  The muon
momentum resolution is found to be 3\% or better for muons with $\pt <
100~\GeVc$.  We apply the muon momentum correction using the ``MusCleFit''
algorithm described in~\cite{CMS_AN_2010-059}. The muon momentum correction and
correction and uncertainty varies as a function of muon \pt and $\eta$. The
effect of the muon momentum correction uncertainty is a small effect in this
analysis compared to the $\tau$ and \MET scale uncertainties.

The uncertainty on the jet energy scale is determined from an analysis of the
\pt balance between photons and jets in $\gamma$ + jets
events~\cite{CMS-PAS-JME-10-010}.  The jet energy scale uncertainties determined
by the JetMET group are applied to tau--jets as well as other jets in the event.
The tau energy scale correction factor is currently taken to be 1.0 with an
uncertainty of 3\%.  The QCD jet energy scale has been measured to within 3\%
uncertainty.  In the future, the energy scale of the tau is expected to be
determined to a much better precision, as the neutral hadronic activity of a
hadronic tau decay is expected to be zero. The jet energy scale of 3\% can be
confidently considered~\cite{CMS-PAS-TAU-11-001} an upper limit\footnote{The tau
energy scale was roughly measured using the invariant mass of the hadronic decay
products and shown to be compatible with 1.0, within 3\%.}, and is used in this
analysis as the tau energy scale uncertainty.

\section{Missing Transverse Energy Correction}
\label{sec:ZRecoilCorr} In practice, the resolution of the reconstructed missing
transverse energy is poor as it is sensitive to the mis--measurement of any
object in the event. Furthermore, a fraction of the particles produced in the
hard collision can be produced in the very forward region, outside of the
fiducial region of the calorimeters.  The resolution of the \MET reconstruction
can be measured in $Z\to\MM$ events. The true \MET in such
events is expected to be zero.  The \MET resolution in simulated $Z\to\MM$
events is found to be smaller (better) than in the data.  

The \MET resolution depends on the ``recoil'' of the $Z$ boson.  The reason for
this effect is that for events where the $Z$ is produced nearly at rest, the
associated recoil products have very small transverse momentum and are produced
at very high pseudorapidity.  The \MET is corrected using a procedure called a
``Z--recoil'' correction, as described in~\cite{CMS_AN_2010-332}.  The
resolution of the \MET is measured in $Z\to\MM$ events in simulation and data.
The difference in the reconstructed \MET resolution in both samples is
parameterized by the magnitude of the transverse momenta of the particles
recoiling against the $Z$.\footnote{The ``recoil'' particles are defined as all
those not identified as $Z$ decay produces. This definition is equivalent to the
total decay product transverse momentum $q_T$ added reconstructed \MET.}  The
reconstructed \MET in the simulated $\ZTT, \ZMM,$ and \WpJets samples is
``smeared'' by a random amount in each event such that the final resolution
matches the observed resolution in the data.

$Z$--recoil corrections are determined as described in~\cite{CMS_AN_2010-332}
and applied to simulated $Z \to \TT$, $Z \rightarrow \mu^+\mu^-$ and $W$ + jets
events, in order to correct for residual differences in $\MET$ response and
resolution between data and Monte Carlo simulation~\cite{CMS_AN_2010-460}. The
corrections are obtained by an unbinned maximum likelihood fit (in data and
simulation) of the transverse recoil vector $\vec{u}_{T} = -\left( \vec{q}_{T} +
\MET \right)$ as function of the transverse momentum $\vec{q}_{T}$ of the
$Z$--boson in directions parallel and perpendicular to the $Z$--boson transverse
momentum vector.  The effect of the $Z$--recoil correction is illustrated in
Figure~\ref{fig:ZrecoilCorrection}.  The uncertainty on the $Z$--recoil
correction factor from the maximum likelihood fit is treated as a systematic
uncertainty in the final result.
\begin{figure}[t]
\setlength{\unitlength}{1mm}
\begin{center}
\begin{picture}(150,52)(0,0)
\put(0.5, 2){\mbox{\includegraphics*[height=52mm]{corrections_chapter/figures/plotMEtPt.pdf}}}
\put(78.0, 2){\mbox{\includegraphics*[height=52mm]{corrections_chapter/figures/plotMEtPt_corrected.pdf}}}
\end{picture}
\caption[$Z$--recoil \MET resolution correction]{Missing transverse energy
reconstructed in $Z \to \mu^{+} \mu^{-}$ events selected in data compared to $Z
\to \mu^{+} \mu^{-}$ events in Monte Carlo simulation before (left) and after
(right) the $Z$--recoil corrections to the $\MET$ resolution are applied.}
\label{fig:ZrecoilCorrection}
\end{center}
\end{figure}

\section{Pile--up Event Weighting}
\label{sec:PUweighting}
The average number of pile--up interactions in the event can effect almost all
aspects of the analysis.  In general, increasing pile--up lowers particle
identification efficiencies and lowers \MET resolution.  It is therefore
important that the distribution of pile--up events in the simulation matches the
distribution found in the data.  Differences in the number of pile--up
interactions between the data (averaged over the analyzed run--range) and
pile-up Monte Carlo samples produced for ``BX156\footnote{The BX156 name comes
from the fact that the pile--up scenario used in this simulation corresponds to
an LHC configuration with 156 bunches.}'' pile--up conditions are corrected for
by reweighting Monte Carlo simulated events according to the number of
reconstructed event vertices, in order to match the distribution measured in a
$W \to \mu \nu$ dataset triggered by the HLT\_Mu15 High Level Trigger path.
Vertices considered for this purpose are required to pass $-24 < z_{vtx} <
+24$~cm, $\left| \rho \right| < 2$~\centi\meter, nDoF $> 4$.  In addition, the
total transverse momenta of all tracks fitted to the vertex is required to
exceed $10$~\GeVc, assuming that ``softer'' vertices have little or no effect on
the ``hard'' event to pass event selection criteria.  The average vertex
multiplicity distribution measured in data is compared to Monte Carlo simulation
with ``BX156'' pile--up conditions in Figure~\ref{fig:pileUpReweighting}.  Both
distributions are similar, resulting in Monte Carlo reweighting factors close to
unity.

\begin{figure}[t]
  \setlength{\unitlength}{1mm}
  \begin{center}
    \begin{picture}(150,52)(0,0)
      \put(0.5, 2){\mbox{\includegraphics*[width=52mm,
      angle=90]{corrections_chapter/figures/vertexMultiplicity.pdf}}}
      \put(78.0, 2){\mbox{\includegraphics*[width=52mm,
      angle=90]{corrections_chapter/figures/vertexMultiplicityReweights.pdf}}}
    \end{picture}
    \caption[Distribution of number of reconstructed primary vertices per
    event]{\captiontext Vertex multiplicity distribution measured in the
    analyzed data--taking period compared to Monte Carlo simulation with
    ``BX156'' pile--up conditions (left) and resulting Monte Carlo reweighting
    factors (right).} \label{fig:pileUpReweighting}
  \end{center}
\end{figure} 



\ifx\master\undefined\input{settings/autocompile}\fi
