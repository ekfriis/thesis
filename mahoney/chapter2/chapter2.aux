\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{Crut88a}
\citation{Crut98d}
\citation{Crut88a}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Prediction, Retrodiction and the Amount of Information Stored in the Present}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:PRATISP}{{1}{1}{Prediction, Retrodiction and the Amount of Information Stored in the Present\relax }{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Introduction}{1}{section.1.1}}
\citation{Crut08a}
\citation{Crut08c}
\citation{Crut08d}
\citation{Crut91b}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Retrodiction}{2}{section.1.2}}
\citation{Crut98d}
\@writefile{lot}{\contentsline {table}{\numberline {1.1}{\ignorespaces  Hidden Process Lattice: The $ {X} $ variables denote the observed process; the $ \mathcal  {S} $ variables, the hidden states. If one scans the observed variables in the positive direction---seeing $ {X} _{-3}$, $ {X} _{-2}$, and $ {X} _{-1}$---then that history takes one to causal state $ { \mathcal  {S} }^{+} _0$. Analogously, if one scans in the reverse direction, then the succession of variables $ {X} _{2}$, $ {X} _{1}$, and $ {X} _{0}$ leads to $ { \mathcal  {S} }^{-} _0$. }}{3}{table.1.1}}
\newlabel{tab:ProcessLattice}{{1.1}{3}{ Hidden Process Lattice: The $\MeasSymbol $ variables denote the observed process; the $\CausalState $ variables, the hidden states. If one scans the observed variables in the positive direction---seeing $\MeasSymbol _{-3}$, $\MeasSymbol _{-2}$, and $\MeasSymbol _{-1}$---then that history takes one to causal state $\FutureCausalState _0$. Analogously, if one scans in the reverse direction, then the succession of variables $\MeasSymbol _{2}$, $\MeasSymbol _{1}$, and $\MeasSymbol _{0}$ leads to $\PastCausalState _0$. \relax }{table.1.1}{}}
\newlabel{prop:FuturePastEqPredict}{{1}{3}{Retrodiction\relax }{Prop.1}{}}
\citation{Crut91b}
\citation{Cove06a}
\citation{Crut08a}
\citation{Crut97a}
\citation{Feld98b}
\citation{Shal98a}
\newlabel{ProcessNotTimeSymmetric}{{2}{4}{Retrodiction\relax }{Prop.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Excess Entropy from Causal States}{4}{section.1.3}}
\newlabel{SpinEEandCmu}{{1.2}{4}{Excess Entropy from Causal States\relax }{equation.1.3.2}{}}
\citation{Crut08a}
\citation{Crut08c}
\citation{Yeun91a}
\citation{Crut08c}
\citation{Crut08a}
\newlabel{CmuEBound}{{1.3}{5}{Excess Entropy from Causal States\relax }{equation.1.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces The generic (un-reduced) I-diagram for 4 random variables, where the names of the variables of interest have been inserted.}}{6}{figure.1.1}}
\newlabel{fig:4variable}{{1.1}{6}{The generic (un-reduced) I-diagram for 4 random variables, where the names of the variables of interest have been inserted}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces The I-diagram for the forward and reverse \unhbox \voidb@x \hbox {$\epsilon $-machines}. Only 5 of the 15 independent information quantities remain. This image is a central reference for the work following.}}{7}{figure.1.2}}
\newlabel{fig:4var_eM}{{1.2}{7}{The I-diagram for the forward and reverse \eMs . Only 5 of the 15 independent information quantities remain. This image is a central reference for the work following}{figure.1.2}{}}
\newlabel{EasCausalMIEq}{{1.4}{7}{Excess Entropy from Causal States\relax }{equation.1.3.4}{}}
\newlabel{EasCausalMI}{{1}{7}{Excess Entropy from Causal States\relax }{equation.1.3.4}{}}
\newlabel{FutureCmuReln}{{1.7}{8}{Excess Entropy from Causal States\relax }{equation.1.3.7}{}}
\newlabel{PastCmuReln}{{1.8}{8}{Excess Entropy from Causal States\relax }{equation.1.3.8}{}}
\citation{Crut98d}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}The Bidirectional Machine}{9}{section.1.4}}
\citation{Crut01a}
\newlabel{SwitchingMapsAreOnto}{{4}{10}{The Bidirectional Machine\relax }{Prop.4}{}}
\citation{Crut98d}
\citation{Shal98a}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}Upper Bounds}{11}{subsection.1.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}Causal Irreversibility}{11}{subsection.1.4.2}}
\citation{Crut91b}
\newlabel{MR_SameEM}{{7}{12}{Causal Irreversibility\relax }{Prop.7}{}}
\newlabel{CI_MicroIrreversible}{{8}{12}{Causal Irreversibility\relax }{Prop.8}{}}
\citation{Shan49a}
\citation{Pack80}
\citation{Cove06a}
\citation{Crut87f}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}Process Crypticity}{13}{subsection.1.4.3}}
\newlabel{Prop:PCisaDistance}{{9}{13}{Process Crypticity\relax }{Prop.9}{}}
\citation{Crut08a}
\citation{Crut08c}
\citation{Crut08d}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Alternative Presentations}{14}{section.1.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces This diagram summarizes the measures and relationships derived in this chapter. The upper part of the figure should already be familiar---some relationships have been added. The bottom three icons illustrate which portions of the above diagram are added (or subtracted) to obtain the three newly defined measures: $ C_\mu ^{\pm } $, $\Xi $, and $\chi ^{\pm }$. These represent the process's bidirectional information storage, irreversibility, and information overhead, respectively.}}{15}{figure.1.3}}
\newlabel{4var_eM_more3}{{1.3}{15}{This diagram summarizes the measures and relationships derived in this chapter. The upper part of the figure should already be familiar---some relationships have been added. The bottom three icons illustrate which portions of the above diagram are added (or subtracted) to obtain the three newly defined measures: $\BiCmu $, $\CI $, and $\BiPC $. These represent the process's bidirectional information storage, irreversibility, and information overhead, respectively}{figure.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}Time-Reversed Presentation}{15}{subsection.1.5.1}}
\citation{Uppe97a}
\newlabel{eqpi}{{10}{16}{Time-Reversed Presentation\relax }{Prop.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}Mixed-State Presentation}{16}{subsection.1.5.2}}
\newlabel{MSP}{{1.5.2}{16}{Mixed-State Presentation\relax }{subsection.1.5.2}{}}
\newlabel{mixedstates}{{1.16}{17}{Mixed-State Presentation\relax }{equation.1.5.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Calculating Excess Entropy}{17}{section.1.6}}
\newlabel{mixedstatesrev}{{1.22}{18}{Calculating Excess Entropy\relax }{equation.1.6.22}{}}
\newlabel{transitionrev}{{1.26}{18}{Calculating Excess Entropy\relax }{equation.1.6.26}{}}
\citation{Cove06a}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Calculational Example}{19}{section.1.7}}
\citation{Uppe97a}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces  The presentations used to calculate the excess entropy for the RnC Process: (a)\nobreakspace  {}$ { M }^{+} $, (b)\nobreakspace  {}\unhbox \voidb@x \hbox {$\mathaccentV {widetilde}365{M}^+ = \mathcal  {T}( { M }^{+} )$}, and (c)\nobreakspace  {}\unhbox \voidb@x \hbox {$ { M }^{-} = \mathcal  {U}(\mathaccentV {widetilde}365{M}^+)$}. Edge labels $t|x$ give the probability \unhbox \voidb@x \hbox {$t = T_{ \mathcal  {R}  \mathcal  {R} ^\prime }^{(x)}$} of making a transition and seeing symbol $x$. }}{21}{figure.1.4}}
\newlabel{fig:RnC}{{1.4}{21}{ The presentations used to calculate the excess entropy for the RnC Process: (a)~$\FutureEM $, (b)~\mbox {$\widetilde {M}^+ = \TR (\FutureEM )$}, and (c)~\mbox {$\PastEM = \MSP (\widetilde {M}^+)$}. Edge labels $t|x$ give the probability \mbox {$t = T_{\AlternateState \AlternateState ^\prime }^{(x)}$} of making a transition and seeing symbol $x$. \relax }{figure.1.4}{}}
\citation{Weis73}
\citation{Crut01a}
\citation{Crut01a}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Examples}{23}{section.1.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}Even Process}{23}{subsection.1.8.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.5}{\ignorespaces  Forward and reverse \unhbox \voidb@x \hbox {$\epsilon $-machines}\ for the Even Process: (a) $ { M }^{+} $ and (b) $ { M }^{-} $. (c) The bidirectional machine $ { M }^{\pm } $. Edge labels are prefixed by the scan direction $\{-,+\}$. }}{24}{figure.1.5}}
\newlabel{fig:EvenProcess}{{1.5}{24}{ Forward and reverse \eMs \ for the Even Process: (a) $\FutureEM $ and (b) $\PastEM $. (c) The bidirectional machine $\BiEM $. Edge labels are prefixed by the scan direction $\{-,+\}$. \relax }{figure.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.6}{\ignorespaces The Even Process's information processing properties---$ C_\mu ^{\pm } $, $ C_\mu ^{+} $, and $\chi ^{+}$---as its self-loop probability $p$ varies. The colored area bounded by the curves show the magnitude of ${\bf  E}$. }}{25}{figure.1.6}}
\newlabel{fig:EP_info}{{1.6}{25}{The Even Process's information processing properties---$\BiCmu $, $\FutureCmu $, and $\FuturePC $---as its self-loop probability $p$ varies. The colored area bounded by the curves show the magnitude of $\EE $. \relax }{figure.1.6}{}}
\citation{Crut01a}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}Golden Mean Process}{26}{subsection.1.8.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.7}{\ignorespaces  Forward and reverse \unhbox \voidb@x \hbox {$\epsilon $-machines}\ for the Golden Mean Process: (a) $ { M }^{+} $ and (b) $ { M }^{-} $. (c) The bidirectional machine $ { M }^{\pm } $. }}{27}{figure.1.7}}
\newlabel{fig:GMP}{{1.7}{27}{ Forward and reverse \eMs \ for the Golden Mean Process: (a) $\FutureEM $ and (b) $\PastEM $. (c) The bidirectional machine $\BiEM $. \relax }{figure.1.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.8}{\ignorespaces The Golden Mean Process's information processing measures---$ C_\mu ^{\pm } $, $ C_\mu ^{+} $, and $\chi ^{+}$---as its self-loop probability $p$ varies. Colored areas bounded by the curves give the magnitude at each $p$ of $\chi ^{-}$, ${\bf  E}$, and $\chi ^{+}$. }}{28}{figure.1.8}}
\newlabel{fig:GMP_info}{{1.8}{28}{The Golden Mean Process's information processing measures---$\BiCmu $, $\FutureCmu $, and $\FuturePC $---as its self-loop probability $p$ varies. Colored areas bounded by the curves give the magnitude at each $p$ of $\PastPC $, $\EE $, and $\FuturePC $. \relax }{figure.1.8}{}}
\citation{Crut08a}
\citation{Crut08a}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.3}Random Insertion Process}{30}{subsection.1.8.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.9}{\ignorespaces  Forward and reverse \unhbox \voidb@x \hbox {$\epsilon $-machines}\ for the RIP with $p=q=1/2$: (a) $ { M }^{+} $ and (b) $ { M }^{-} $. (c) The bidirectional machine $ { M }^{\pm } $ also for $p = q = 1/2$. (Reprinted with permission from Refs.\nobreakspace  {}\cite  {Crut08a}.) }}{31}{figure.1.9}}
\newlabel{fig:RIP}{{1.9}{31}{ Forward and reverse \eMs \ for the RIP with $p=q=1/2$: (a) $\FutureEM $ and (b) $\PastEM $. (c) The bidirectional machine $\BiEM $ also for $p = q = 1/2$. (Reprinted with permission from Refs.~\cite {Crut08a}.) \relax }{figure.1.9}{}}
\citation{Fras90b}
\citation{Casd91a}
\citation{Spro03a}
\citation{Kant06a}
\citation{Arno96}
\citation{Crut97a}
\citation{Feld98b}
\citation{Tono94a}
\citation{Bial00a}
\citation{Ebel94c}
\citation{Debo08a}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Conclusions}{32}{section.1.9}}
\bibstyle{../bibliography/expanded}
\bibdata{../bibliography/references}
\@writefile{lof}{\contentsline {figure}{\numberline {1.10}{\ignorespaces The Random Insertion Process's information processing measures as its two probability parameters $p$ and $q$ vary. The central square shows the $(p,q)$ parameter space, with solid and dashed lines indicating the paths in parameter space for each of the other information versus parameter plots. The latter's vertical axes are scaled so that two tick marks measure $1$ bit of information. The inset legend indicates the class of process illustrated by the paths. Colored areas give the magnitude of $\chi ^{-}$, ${\bf  E}$, and $\chi ^{+}$. }}{35}{figure.1.10}}
\newlabel{fig:RIP_info}{{1.10}{35}{The Random Insertion Process's information processing measures as its two probability parameters $p$ and $q$ vary. The central square shows the $(p,q)$ parameter space, with solid and dashed lines indicating the paths in parameter space for each of the other information versus parameter plots. The latter's vertical axes are scaled so that two tick marks measure $1$ bit of information. The inset legend indicates the class of process illustrated by the paths. Colored areas give the magnitude of $\PastPC $, $\EE $, and $\FuturePC $. \relax }{figure.1.10}{}}
